from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from groq import Groq
import os

TOKEN = os.getenv("TOKEN")
GROQ_API_KEY = "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"
RENDER_URL = os.getenv("RENDER_URL")  # URL que o Render vai gerar

client = Groq(api_key=GROQ_API_KEY)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üî∑‚ú® *Bem-vindo ao Assistente OMR Claro* ‚ú®üî∑\n\n"
        "Sou seu suporte inteligente com IA para opera√ß√µes em campo.\n\n"
        "üì° *Huawei* (BBU, RRU, RF)\n"
        "üì∂ *MW* Ceragon | Ericsson\n"
        "üåê *Roteadores* Cisco ASR-920 | ZTE\n"
        "üîå *Energia* e infraestrutura\n"
        "üìç *Localiza√ß√£o* de sites + rotas\n"
        "üì¶ *Gest√£o* de sobressalentes\n"
        "‚è∞ *Lembretes* e tarefas\n\n"
        "Digite sua d√∫vida! üëá",
        parse_mode="Markdown"
    )

async def responder(update: Update, context: ContextTypes.DEFAULT_TYPE):
    mensagem_usuario = update.message.text

    # Envia para a IA
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "system",
                "content": (
                    "Voc√™ √© um assistente t√©cnico especializado em OMR da Claro no Paran√° e Santa Catarina. "
                    "Ajuda com: Huawei RF (BBU 5900/5910/5920, RRU 3900/3910/5900), "
                    "MW (Ceragon CeraOS/LACP, Ericsson MINI-LINK), "
                    "roteadores Cisco ASR-920 e ZTE M6000-2S16, "
                    "energia (retificadores, baterias, A/C, geradores), "
                    "infraestrutura (aterramento, torres, acesso), "
                    "lembretes, tarefas e organiza√ß√£o. "
                    "Sempre pergunte o modelo do equipamento quando necess√°rio. "
                    "Seja direto, claro, t√©cnico e use emojis quando apropriado. "
                    "Formate respostas com Markdown quando √∫til."
                )
            },
            {
                "role": "user",
                "content": mensagem_usuario
            }
        ],
        model="llama-3.1-70b-versatile",
        temperature=0.3,
    )

    resposta = chat_completion.choices[0].message.content
    await update.message.reply_text(resposta, parse_mode="Markdown")

async def main():
    app = Application.builder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, responder))

    # WEBHOOK (para Render Web Service)
    await app.bot.set_webhook(url=f"{RENDER_URL}/{TOKEN}")

    # Inicia o servidor
    await app.run_webhook(
        listen="0.0.0.0",
        port=int(os.getenv("PORT", 10000)),
        url_path=TOKEN,
        webhook_url=f"{RENDER_URL}/{TOKEN}"
    )

if __name__ == '__main__':
    import asyncio
    asyncio.run(main())
